{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJ4NvbsfY91S"
      },
      "source": [
        "**7장 - 앙상블 학습과 랜덤 포레스트**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0hrEOmVY91V"
      },
      "source": [
        "_이 노트북에는 7장의 모든 샘플 코드와 연습 문제에 대한 솔루션이 포함되어 있습니다._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3honfB_Y91V"
      },
      "source": [
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/rickiepark/handson-ml3/blob/main/07_ensemble_learning_and_random_forests.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zesZe-EeY91W",
        "tags": []
      },
      "source": [
        "# 7.0 설정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4VCZtT8Y91W"
      },
      "source": [
        "이 프로젝트에는 파이썬 3.7 이상이 필요합니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8EERz3L4Y91X"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "assert sys.version_info >= (3, 7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMOp4LIPY91X"
      },
      "source": [
        "또한 사이킷런 ≥ 1.0.1이 필요합니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ICkXYqaNY91Y"
      },
      "outputs": [],
      "source": [
        "from packaging import version\n",
        "import sklearn\n",
        "\n",
        "assert version.parse(sklearn.__version__) >= version.parse(\"1.0.1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4gbPyRwY91Y"
      },
      "source": [
        "이전 챕터에서와 마찬가지로 기본 글꼴 크기를 정의하여 그림을 더 예쁘게 만들어 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aME7BU_fY91Y",
        "outputId": "acc483f7-2609-4c9c-9ede-e59e99858d73"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rc('font', size=14)\n",
        "plt.rc('axes', labelsize=14, titlesize=14)\n",
        "plt.rc('legend', fontsize=14)\n",
        "plt.rc('xtick', labelsize=10)\n",
        "plt.rc('ytick', labelsize=10)\n",
        "\n",
        "import sys\n",
        "# 코랩의 경우 나눔 폰트를 설치합니다.\n",
        "if 'google.colab' in sys.modules:\n",
        "    !sudo apt-get -qq -y install fonts-nanum\n",
        "    import matplotlib.font_manager as fm\n",
        "    font_files = fm.findSystemFonts(fontpaths=['/usr/share/fonts/truetype/nanum'])\n",
        "    for fpath in font_files:\n",
        "        fm.fontManager.addfont(fpath)\n",
        "\n",
        "# 나눔 폰트를 사용합니다.\n",
        "import matplotlib\n",
        "\n",
        "matplotlib.rc('font', family='NanumBarunGothic')\n",
        "matplotlib.rcParams['axes.unicode_minus'] = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-0b8JYYY91Z"
      },
      "source": [
        "그리고 아직 존재하지 않는 경우 `images/ensembles` 폴더를 만들고, 이 노트북을 통해 책에 사용할 그림을 고해상도로 저장하는 데 사용되는 `save_fig()` 함수를 정의해 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Eonw0HPWY91Z"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "IMAGES_PATH = Path() / \"images\" / \"ensembles\"\n",
        "IMAGES_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = IMAGES_PATH / f\"{fig_id}.{fig_extension}\"\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEy0VLcMY91Z"
      },
      "source": [
        "# 7.1 투표 기반 분류기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "Dy-VIXtXY91Z",
        "outputId": "e5610457-d404-4a7a-b3c3-793e6accb34e"
      },
      "outputs": [],
      "source": [
        "# 추가 코드 - 이 셀은 그림 7-3을 생성하고 저장합니다.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "heads_proba = 0.51\n",
        "np.random.seed(42)\n",
        "coin_tosses = (np.random.rand(10000, 10) < heads_proba).astype(np.int32)\n",
        "cumulative_heads = coin_tosses.cumsum(axis=0)\n",
        "cumulative_heads_ratio = cumulative_heads / np.arange(1, 10001).reshape(-1, 1)\n",
        "\n",
        "plt.figure(figsize=(8, 3.5))\n",
        "plt.plot(cumulative_heads_ratio)\n",
        "plt.plot([0, 10000], [0.51, 0.51], \"k--\", linewidth=2, label=\"51%\")\n",
        "plt.plot([0, 10000], [0.5, 0.5], \"k-\", label=\"50%\")\n",
        "plt.xlabel(\"동전을 던진 횟수\")\n",
        "plt.ylabel(\"앞면이 나온 비율\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.axis([0, 10000, 0.42, 0.58])\n",
        "plt.grid()\n",
        "save_fig(\"law_of_large_numbers_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab194p0eY91a"
      },
      "source": [
        "투표 기반 분류기를 만들어 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "GPLFV6jJY91a",
        "outputId": "284858eb-d875-443c-a43d-002ef3cfd30c"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_moons\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "X, y = make_moons(n_samples=500, noise=0.30, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('lr', LogisticRegression(random_state=42)),\n",
        "        ('rf', RandomForestClassifier(random_state=42)),\n",
        "        ('svc', SVC(random_state=42))\n",
        "    ]\n",
        ")\n",
        "voting_clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trydL9HNY91a",
        "outputId": "942e8ba1-12ce-4c39-bb0d-3bdd80a0b6e9"
      },
      "outputs": [],
      "source": [
        "for name, clf in voting_clf.named_estimators_.items():\n",
        "    print(name, \"=\", clf.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZrRtf3DY91a",
        "outputId": "f3dbc9df-37ac-4994-c35b-e1f676fcc733"
      },
      "outputs": [],
      "source": [
        "voting_clf.predict(X_test[:1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xNqIwgAY91a",
        "outputId": "99761064-dd9b-4aec-840f-909f8d97226d"
      },
      "outputs": [],
      "source": [
        "[clf.predict(X_test[:1]) for clf in voting_clf.estimators_]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvQo7JaLY91a",
        "outputId": "b0a0e1f1-4c85-4ca5-99bb-e2bd24cbc02b"
      },
      "outputs": [],
      "source": [
        "voting_clf.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XysYZMVbY91b"
      },
      "source": [
        "이제 간접 투표를 사용해 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwMnoFKwY91b",
        "outputId": "f9e95b7f-3ded-4d05-f6ce-95abb257a816"
      },
      "outputs": [],
      "source": [
        "voting_clf.voting = \"soft\"\n",
        "voting_clf.named_estimators[\"svc\"].probability = True\n",
        "voting_clf.fit(X_train, y_train)\n",
        "voting_clf.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MaYsBesY91b"
      },
      "source": [
        "# 7.2 배깅과 페이스팅\n",
        "\n",
        "## 7.2.1 사이킷런의 배깅과 페이스팅"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "id": "7sqe3AH5Y91b",
        "outputId": "2e5d8564-8984-41e9-c421-e0d13434b5b2"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=500,\n",
        "                            max_samples=100, n_jobs=-1, random_state=42)\n",
        "bag_clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "id": "eW0m90dDY91b",
        "outputId": "f5ddc1f6-1860-4a91-f629-326f976578eb"
      },
      "outputs": [],
      "source": [
        "# 추가 코드 - 이 셀은 그림 7-5를 생성하고 저장합니다.\n",
        "\n",
        "def plot_decision_boundary(clf, X, y, alpha=1.0):\n",
        "    axes=[-1.5, 2.4, -1, 1.5]\n",
        "    x1, x2 = np.meshgrid(np.linspace(axes[0], axes[1], 100),\n",
        "                         np.linspace(axes[2], axes[3], 100))\n",
        "    X_new = np.c_[x1.ravel(), x2.ravel()]\n",
        "    y_pred = clf.predict(X_new).reshape(x1.shape)\n",
        "\n",
        "    plt.contourf(x1, x2, y_pred, alpha=0.3 * alpha, cmap='Wistia')\n",
        "    plt.contour(x1, x2, y_pred, cmap=\"Greys\", alpha=0.8 * alpha)\n",
        "    colors = [\"#78785c\", \"#c47b27\"]\n",
        "    markers = (\"o\", \"^\")\n",
        "    for idx in (0, 1):\n",
        "        plt.plot(X[:, 0][y == idx], X[:, 1][y == idx],\n",
        "                 color=colors[idx], marker=markers[idx], linestyle=\"none\")\n",
        "    plt.axis(axes)\n",
        "    plt.xlabel(r\"$x_1$\")\n",
        "    plt.ylabel(r\"$x_2$\", rotation=0)\n",
        "\n",
        "tree_clf = DecisionTreeClassifier(random_state=42)\n",
        "tree_clf.fit(X_train, y_train)\n",
        "\n",
        "fig, axes = plt.subplots(ncols=2, figsize=(10, 4), sharey=True)\n",
        "plt.sca(axes[0])\n",
        "plot_decision_boundary(tree_clf, X_train, y_train)\n",
        "plt.title(\"결정 트리\")\n",
        "plt.sca(axes[1])\n",
        "plot_decision_boundary(bag_clf, X_train, y_train)\n",
        "plt.title(\"배깅을 사용한 결정 트리\")\n",
        "plt.ylabel(\"\")\n",
        "save_fig(\"decision_tree_without_and_with_bagging_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCmI9ke9Y91b"
      },
      "source": [
        "## 7.2.2 OOB 평가"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UV99ms_8Y91b",
        "outputId": "137e2e52-bdd0-4825-9694-6f2e10bcad92"
      },
      "outputs": [],
      "source": [
        "bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=500,\n",
        "                            oob_score=True, n_jobs=-1, random_state=42)\n",
        "bag_clf.fit(X_train, y_train)\n",
        "bag_clf.oob_score_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B39Jkp0tY91b",
        "outputId": "2da43909-e771-4b18-ed3b-fb2e22b0b4e6"
      },
      "outputs": [],
      "source": [
        "bag_clf.oob_decision_function_[:3]  # probas for the first 3 instances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ba-AyMyY91c",
        "outputId": "c1d2ba17-4ca0-4f16-e044-9c58b995c8f3",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_pred = bag_clf.predict(X_test)\n",
        "accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0XogWuMY91c"
      },
      "source": [
        "크기가 _m_인 데이터셋에서 하나의 샘플을 무작위로 뽑는 경우, 데이터셋의 각 샘플이 선택될 확률은 1/_m_ 이므로 선택되지 않을 확률은 1 - 1/_m_ 입니다. 중복을 허용하여 _m_ 개의 샘플을 뽑는 경우, 모든 추첨은 독립적이므로 각 샘플의 선택되지 않을 확률은 (1 - 1/_m_)<sup>_m_</sup> 입니다. 이제 _m_ 이 무한대에 가까워지면 exp(_x_)가 (1 + _x_/_m_)<sup>_m_</sup>의 극한과 같다는 사실을 이용해 보겠습니다. 따라서 _m_ 이 크면 OOB 샘플의 비율은 약 exp(-1) ≈ 0.37이 됩니다. 따라서 대략 63%(1 - 0.37)가 샘플링됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVY5DtVeY91c",
        "outputId": "d7bf0486-bc8e-4430-9abd-68161e6a5722"
      },
      "outputs": [],
      "source": [
        "# 추가 코드 - 63% 확률을 계산하는 방법을 보여줍니다.\n",
        "print(1 - (1 - 1 / 1000) ** 1000)\n",
        "print(1 - np.exp(-1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_WOPwOZY91c"
      },
      "source": [
        "# 7.4 랜덤 포레스트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "H7sjQgAYY91c"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16,\n",
        "                                 n_jobs=-1, random_state=42)\n",
        "rnd_clf.fit(X_train, y_train)\n",
        "y_pred_rf = rnd_clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czXS_oa4Y91c"
      },
      "source": [
        "랜덤 포레스트는 결정 트리의 배깅과 같습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "JmOywZMFY91c"
      },
      "outputs": [],
      "source": [
        "bag_clf = BaggingClassifier(\n",
        "    DecisionTreeClassifier(max_features=\"sqrt\", max_leaf_nodes=16),\n",
        "    n_estimators=500, n_jobs=-1, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVBTYTq9Y91c",
        "outputId": "1b751b22-fd68-4121-f7e5-8c3c56aaac5c"
      },
      "outputs": [],
      "source": [
        "# 추가 코드 - 예측이 동일한지 확인합니다.\n",
        "bag_clf.fit(X_train, y_train)\n",
        "y_pred_bag = bag_clf.predict(X_test)\n",
        "np.all(y_pred_bag == y_pred_rf)  # 동일한 예측"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCbnzzLhY91c"
      },
      "source": [
        "## 7.4.2 특성 중요도"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMintuTaY91c",
        "outputId": "328a7864-ce1d-4f66-b40d-57c0743c2f48"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris = load_iris(as_frame=True)\n",
        "rnd_clf = RandomForestClassifier(n_estimators=500, random_state=42)\n",
        "rnd_clf.fit(iris.data, iris.target)\n",
        "for score, name in zip(rnd_clf.feature_importances_, iris.data.columns):\n",
        "    print(round(score, 2), name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "SyAz9hiZY91d",
        "outputId": "7ba43b0b-b676-4e4a-8d7a-abb3aa91e17e"
      },
      "outputs": [],
      "source": [
        "# 추가 코드 - 이 셀은 그림 7-6을 생성하고 저장합니다.\n",
        "\n",
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "# 사이킷런 1.4버전에서 parser 매개변수 기본값이 'liac-arff'에서 'auto'로 바뀌었습니다.\n",
        "# 이전 버전에서도 동일한 결과를 내도록 명시적으로 'auto'로 지정합니다.\n",
        "X_mnist, y_mnist = fetch_openml('mnist_784', return_X_y=True,\n",
        "                                as_frame=False, parser='auto')\n",
        "\n",
        "rnd_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rnd_clf.fit(X_mnist, y_mnist)\n",
        "\n",
        "heatmap_image = rnd_clf.feature_importances_.reshape(28, 28)\n",
        "plt.imshow(heatmap_image, cmap=\"hot\")\n",
        "cbar = plt.colorbar(ticks=[rnd_clf.feature_importances_.min(),\n",
        "                           rnd_clf.feature_importances_.max()])\n",
        "cbar.ax.set_yticklabels(['중요하지 않음', '매우 중요'], fontsize=14)\n",
        "plt.axis(\"off\")\n",
        "save_fig(\"mnist_feature_importance_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kt56w10FY91g"
      },
      "source": [
        "# 7.5 부스팅\n",
        "\n",
        "## 7.5.1 AdaBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "id": "L8duNqBqY91g",
        "outputId": "4a42554d-41f6-49c6-d0b7-5c6f58067b81"
      },
      "outputs": [],
      "source": [
        "# 추가 코드 - 이 셀은 그림 7-8을 생성하고 저장합니다.\n",
        "\n",
        "m = len(X_train)\n",
        "\n",
        "fig, axes = plt.subplots(ncols=2, figsize=(10, 4), sharey=True)\n",
        "for subplot, learning_rate in ((0, 1), (1, 0.5)):\n",
        "    sample_weights = np.ones(m) / m\n",
        "    plt.sca(axes[subplot])\n",
        "    for i in range(5):\n",
        "        svm_clf = SVC(C=0.2, gamma=0.6, random_state=42)\n",
        "        svm_clf.fit(X_train, y_train, sample_weight=sample_weights * m)\n",
        "        y_pred = svm_clf.predict(X_train)\n",
        "\n",
        "        error_weights = sample_weights[y_pred != y_train].sum()\n",
        "        r = error_weights / sample_weights.sum()  # equation 7-1\n",
        "        alpha = learning_rate * np.log((1 - r) / r)  # equation 7-2\n",
        "        sample_weights[y_pred != y_train] *= np.exp(alpha)  # equation 7-3\n",
        "        sample_weights /= sample_weights.sum()  # normalization step\n",
        "\n",
        "        plot_decision_boundary(svm_clf, X_train, y_train, alpha=0.4)\n",
        "        plt.title(f\"learning_rate = {learning_rate}\")\n",
        "    if subplot == 0:\n",
        "        plt.text(-0.75, -0.95, \"1\", fontsize=16)\n",
        "        plt.text(-1.05, -0.95, \"2\", fontsize=16)\n",
        "        plt.text(1.0, -0.95, \"3\", fontsize=16)\n",
        "        plt.text(-1.45, -0.5, \"4\", fontsize=16)\n",
        "        plt.text(1.36,  -0.95, \"5\", fontsize=16)\n",
        "    else:\n",
        "        plt.ylabel(\"\")\n",
        "\n",
        "save_fig(\"boosting_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "id": "yoq-DXPEY91h",
        "outputId": "6fb4a4f5-f903-4df3-9bbb-d218ee9f890d"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "ada_clf = AdaBoostClassifier(\n",
        "    DecisionTreeClassifier(max_depth=1), n_estimators=30,\n",
        "    learning_rate=0.5, random_state=42)\n",
        "ada_clf.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "BEmY0JL2Y91h",
        "outputId": "cdbd5315-ca2b-42e4-9ecb-b550558c7bff"
      },
      "outputs": [],
      "source": [
        "# 추가 코드 - AdaBoost 분류기에 대한 결정 경계가 어떻게 보이는지 궁금한 경우\n",
        "plot_decision_boundary(ada_clf, X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVWOzbKjY91h"
      },
      "source": [
        "## 7.5.2 그레이디언트 부스팅"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_qIOqRbY91h"
      },
      "source": [
        "간단한 2차방정식 데이터셋을 만들고 여기에 `DecisionTreeRegressor`를 훈련시켜 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "XciINxFdY91h",
        "outputId": "f06de67a-dc32-4460-84fa-5e9d849ac9cc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "np.random.seed(42)\n",
        "X = np.random.rand(100, 1) - 0.5\n",
        "y = 3 * X[:, 0] ** 2 + 0.05 * np.random.randn(100)  # y = 3x² + Gaussian noise\n",
        "\n",
        "tree_reg1 = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
        "tree_reg1.fit(X, y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iw4Y0NmiY91h"
      },
      "source": [
        "이제 이전 예측기가 만든 잔여 오차에 대해 다른 결정 트리 회귀를 훈련해 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "4YWH1oJwY91i",
        "outputId": "c5ee87c8-7007-449c-964b-36fed6fd9419"
      },
      "outputs": [],
      "source": [
        "y2 = y - tree_reg1.predict(X)\n",
        "tree_reg2 = DecisionTreeRegressor(max_depth=2, random_state=43)\n",
        "tree_reg2.fit(X, y2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "97LFbRc0Y91i",
        "outputId": "aa4bb898-62fd-4048-9051-04eeb0d7f9c9"
      },
      "outputs": [],
      "source": [
        "y3 = y2 - tree_reg2.predict(X)\n",
        "tree_reg3 = DecisionTreeRegressor(max_depth=2, random_state=44)\n",
        "tree_reg3.fit(X, y3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lOWO5XAY91i",
        "outputId": "0006aed6-3b08-472e-9c2e-3fef100c2d0d"
      },
      "outputs": [],
      "source": [
        "X_new = np.array([[-0.4], [0.], [0.5]])\n",
        "sum(tree.predict(X_new) for tree in (tree_reg1, tree_reg2, tree_reg3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ORYxHFdpY91i",
        "outputId": "135c4339-775f-4d82-ad0f-c6ce70097bf3"
      },
      "outputs": [],
      "source": [
        "# 추가 코드 - 이 셀은 그림 7-9를 생성하고 저장합니다.\n",
        "\n",
        "def plot_predictions(regressors, X, y, axes, style,\n",
        "                     label=None, data_style=\"b.\", data_label=None):\n",
        "    x1 = np.linspace(axes[0], axes[1], 500)\n",
        "    y_pred = sum(regressor.predict(x1.reshape(-1, 1))\n",
        "                 for regressor in regressors)\n",
        "    plt.plot(X[:, 0], y, data_style, label=data_label)\n",
        "    plt.plot(x1, y_pred, style, linewidth=2, label=label)\n",
        "    if label or data_label:\n",
        "        plt.legend(loc=\"upper center\")\n",
        "    plt.axis(axes)\n",
        "\n",
        "plt.figure(figsize=(11, 11))\n",
        "\n",
        "plt.subplot(3, 2, 1)\n",
        "plot_predictions([tree_reg1], X, y, axes=[-0.5, 0.5, -0.2, 0.8], style=\"g-\",\n",
        "                 label=\"$h_1(x_1)$\", data_label=\"훈련 세트\")\n",
        "plt.ylabel(\"$y$  \", rotation=0)\n",
        "plt.title(\"잔여 오차와 트리의 예측\")\n",
        "\n",
        "plt.subplot(3, 2, 2)\n",
        "plot_predictions([tree_reg1], X, y, axes=[-0.5, 0.5, -0.2, 0.8], style=\"r-\",\n",
        "                 label=\"$h(x_1) = h_1(x_1)$\", data_label=\"훈련 세트\")\n",
        "plt.title(\"앙상블의 예측\")\n",
        "\n",
        "plt.subplot(3, 2, 3)\n",
        "plot_predictions([tree_reg2], X, y2, axes=[-0.5, 0.5, -0.4, 0.6], style=\"g-\",\n",
        "                 label=\"$h_2(x_1)$\", data_style=\"k+\",\n",
        "                 data_label=\"잔여 오차: $y - h_1(x_1)$\")\n",
        "plt.ylabel(\"$y$  \", rotation=0)\n",
        "\n",
        "plt.subplot(3, 2, 4)\n",
        "plot_predictions([tree_reg1, tree_reg2], X, y, axes=[-0.5, 0.5, -0.2, 0.8],\n",
        "                  style=\"r-\", label=\"$h(x_1) = h_1(x_1) + h_2(x_1)$\")\n",
        "\n",
        "plt.subplot(3, 2, 5)\n",
        "plot_predictions([tree_reg3], X, y3, axes=[-0.5, 0.5, -0.4, 0.6], style=\"g-\",\n",
        "                 label=\"$h_3(x_1)$\", data_style=\"k+\",\n",
        "                 data_label=\"잔여 오차: $y - h_1(x_1) - h_2(x_1)$\")\n",
        "plt.xlabel(\"$x_1$\")\n",
        "plt.ylabel(\"$y$  \", rotation=0)\n",
        "\n",
        "plt.subplot(3, 2, 6)\n",
        "plot_predictions([tree_reg1, tree_reg2, tree_reg3], X, y,\n",
        "                 axes=[-0.5, 0.5, -0.2, 0.8], style=\"r-\",\n",
        "                 label=\"$h(x_1) = h_1(x_1) + h_2(x_1) + h_3(x_1)$\")\n",
        "plt.xlabel(\"$x_1$\")\n",
        "\n",
        "save_fig(\"gradient_boosting_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gIGpKIzY91i"
      },
      "source": [
        "이제 그레이디언트 부스팅 회귀를 시도해 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "Fc-LybNdY91i",
        "outputId": "1c326b80-d2d9-4e94-d4cf-fcaa27e0371b"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=3,\n",
        "                                 learning_rate=1.0, random_state=42)\n",
        "gbrt.fit(X, y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "ooYJy75LY91j",
        "outputId": "ee452d0d-ebc2-4336-eafe-340c0eb6a0c2"
      },
      "outputs": [],
      "source": [
        "gbrt_best = GradientBoostingRegressor(\n",
        "    max_depth=2, learning_rate=0.05, n_estimators=500,\n",
        "    n_iter_no_change=10, random_state=42)\n",
        "gbrt_best.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KH4FEsuWY91j",
        "outputId": "d0e3fa44-231d-49e1-b581-6a68fd0cfd93"
      },
      "outputs": [],
      "source": [
        "gbrt_best.n_estimators_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "id": "SmFX_vumY91j",
        "outputId": "bab1b820-5db8-40fc-bc29-a71f614d92ba"
      },
      "outputs": [],
      "source": [
        "# 추가 코드 - 이 셀은 그림 7-10을 생성하고 저장합니다.\n",
        "\n",
        "fig, axes = plt.subplots(ncols=2, figsize=(10, 4), sharey=True)\n",
        "\n",
        "plt.sca(axes[0])\n",
        "plot_predictions([gbrt], X, y, axes=[-0.5, 0.5, -0.1, 0.8], style=\"r-\",\n",
        "                 label=\"앙상블의 예측\")\n",
        "plt.title(f\"learning_rate={gbrt.learning_rate}, \"\n",
        "          f\"n_estimators={gbrt.n_estimators_}\")\n",
        "plt.xlabel(\"$x_1$\")\n",
        "plt.ylabel(\"$y$\", rotation=0)\n",
        "\n",
        "plt.sca(axes[1])\n",
        "plot_predictions([gbrt_best], X, y, axes=[-0.5, 0.5, -0.1, 0.8], style=\"r-\")\n",
        "plt.title(f\"learning_rate={gbrt_best.learning_rate}, \"\n",
        "          f\"n_estimators={gbrt_best.n_estimators_}\")\n",
        "plt.xlabel(\"$x_1$\")\n",
        "\n",
        "save_fig(\"gbrt_learning_rate_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "eAIXwU6aY91j"
      },
      "outputs": [],
      "source": [
        "# 추가 코드 - 2장에서 설명했습니다.\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tarfile\n",
        "import urllib.request\n",
        "\n",
        "def load_housing_data():\n",
        "    tarball_path = Path(\"datasets/housing.tgz\")\n",
        "    if not tarball_path.is_file():\n",
        "        Path(\"datasets\").mkdir(parents=True, exist_ok=True)\n",
        "        url = \"https://github.com/ageron/data/raw/main/housing.tgz\"\n",
        "        urllib.request.urlretrieve(url, tarball_path)\n",
        "        with tarfile.open(tarball_path) as housing_tarball:\n",
        "            housing_tarball.extractall(path=\"datasets\")\n",
        "    return pd.read_csv(Path(\"datasets/housing/housing.csv\"))\n",
        "\n",
        "housing = load_housing_data()\n",
        "\n",
        "train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)\n",
        "housing_labels = train_set[\"median_house_value\"]\n",
        "housing = train_set.drop(\"median_house_value\", axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "opUM5h4IY91j",
        "outputId": "e54d8341-2b85-40aa-bae2-40844eb60b78"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.ensemble import HistGradientBoostingRegressor\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "hgb_reg = make_pipeline(\n",
        "    make_column_transformer((OrdinalEncoder(), [\"ocean_proximity\"]),\n",
        "                            remainder=\"passthrough\"),\n",
        "    HistGradientBoostingRegressor(categorical_features=[0], random_state=42)\n",
        ")\n",
        "hgb_reg.fit(housing, housing_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byI-9gksY91j",
        "outputId": "ff56d2cd-963a-4d06-d54c-80be513ff36e"
      },
      "outputs": [],
      "source": [
        "# 추가 코드 - hgb_reg 모델에 대한 RMSE 통계를 평가합니다.\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "hgb_rmses = -cross_val_score(hgb_reg, housing, housing_labels,\n",
        "                             scoring=\"neg_root_mean_squared_error\", cv=10)\n",
        "pd.Series(hgb_rmses).describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnB-uxLtY91k"
      },
      "source": [
        "# 7.6 스태킹"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "oUd_dKVUY91k",
        "outputId": "14a99c79-3666-4f91-e7ec-d6ef1592cc37"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import StackingClassifier\n",
        "\n",
        "stacking_clf = StackingClassifier(\n",
        "    estimators=[\n",
        "        ('lr', LogisticRegression(random_state=42)),\n",
        "        ('rf', RandomForestClassifier(random_state=42)),\n",
        "        ('svc', SVC(probability=True, random_state=42))\n",
        "    ],\n",
        "    final_estimator=RandomForestClassifier(random_state=43),\n",
        "    cv=5  # 교차 검증 폴드 수\n",
        ")\n",
        "stacking_clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85N9corVY91k",
        "outputId": "ba7c9241-029e-4682-efc3-571546c29f99"
      },
      "outputs": [],
      "source": [
        "stacking_clf.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4Zt-QgeY91k"
      },
      "source": [
        "# 연습문제 해답"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTQtKhiOY91k"
      },
      "source": [
        "## 1. to 7."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDHhz4f4Y91k"
      },
      "source": [
        "부록 A 참조"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20pzt2EWY91k"
      },
      "source": [
        "## 8. 투표 기반 분류기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eq2FVVW0Y91k"
      },
      "source": [
        "문제: _MNIST 데이터를 불러들여 훈련 세트, 검증 세트, 테스트 세트로 나눕니다(예를 들면 훈련에 50,000개 샘플, 검증에 10,000개 샘플, 테스트에 10,000개 샘플)._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpZCykJxY91k"
      },
      "source": [
        "MNIST 데이터셋은 앞서 로드했습니다. 이 데이터셋은 이미 훈련 세트(처음 60,000개의 샘플)와 테스트 세트(마지막 10,000개의 샘플)로 분할되어 있으며, 훈련 세트는 이미 뒤섞여 있습니다. 따라서 처음 50,000개의 샘플을 새 훈련 세트에, 다음 10,000개의 샘플을 검증 세트에, 마지막 10,000개의 샘플을 테스트 세트에 사용하기만 하면 됩니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "X-GkhHoOY91k"
      },
      "outputs": [],
      "source": [
        "X_train, y_train = X_mnist[:50_000], y_mnist[:50_000]\n",
        "X_valid, y_valid = X_mnist[50_000:60_000], y_mnist[50_000:60_000]\n",
        "X_test, y_test = X_mnist[60_000:], y_mnist[60_000:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWS1cEKuY91l"
      },
      "source": [
        "문제: _그런 다음 랜덤 포레스트 분류기, 엑스트라 트리 분류기, SVM 분류기 같은 여러 종류의 분류기를 훈련시킵니다._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "xtiiNIHGY91l"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.neural_network import MLPClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23LsViXtY91l"
      },
      "source": [
        "사이킷런 1.5에서 `LinearSVC`의 `dual` 매개변수 기본값이 `True`에서 `\"auto\"`로 바뀔 예정입니다. 동일한 결과가 유지되도록 명시적으로 `True`로 지정합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "BS455CeCY91l"
      },
      "outputs": [],
      "source": [
        "random_forest_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "extra_trees_clf = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
        "svm_clf = LinearSVC(max_iter=100, tol=20, dual=True, random_state=42)\n",
        "mlp_clf = MLPClassifier(random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksPqfE94Y91l",
        "outputId": "a877dec2-7159-4676-cd6c-cb578086ba87"
      },
      "outputs": [],
      "source": [
        "estimators = [random_forest_clf, extra_trees_clf, svm_clf, mlp_clf]\n",
        "for estimator in estimators:\n",
        "    print(\"훈련 모델:\", estimator)\n",
        "    estimator.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqAldcseY91l",
        "outputId": "15341519-e7e2-4b4b-81dd-78930cb23b7c"
      },
      "outputs": [],
      "source": [
        "[estimator.score(X_valid, y_valid) for estimator in estimators]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkPU7DnlY91l"
      },
      "source": [
        "선형 SVM은 다른 분류기보다 성능이 훨씬 뛰어납니다. 하지만 투표 기반 분류기의 성능을 향상시킬 수 있으므로 그대로 둡니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKma-ACoY91l"
      },
      "source": [
        "문제: _그리고 검증 세트에서 개개의 분류기보다 더 높은 성능을 내도록 이들을 간접 또는 직접 투표 방법을 사용해 앙상블로 연결해보세요._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "wRmIeurlY91m"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import VotingClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "vxNjvEdjY91m"
      },
      "outputs": [],
      "source": [
        "named_estimators = [\n",
        "    (\"random_forest_clf\", random_forest_clf),\n",
        "    (\"extra_trees_clf\", extra_trees_clf),\n",
        "    (\"svm_clf\", svm_clf),\n",
        "    (\"mlp_clf\", mlp_clf),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "ls0_OQCqY91m"
      },
      "outputs": [],
      "source": [
        "voting_clf = VotingClassifier(named_estimators)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "2gz5obqFY91m",
        "outputId": "3ca013f0-861f-4270-bf6c-e4d35438cfd4"
      },
      "outputs": [],
      "source": [
        "voting_clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "supW-my3Y91m",
        "outputId": "cb49d8b4-39f4-4261-83a2-86f873a5aca6"
      },
      "outputs": [],
      "source": [
        "voting_clf.score(X_valid, y_valid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0jkmBnEY91m"
      },
      "source": [
        "`VotingClassifier`는 각 분류기의 복제본을 만들어 원래 클래스 이름이 아닌 클래스 인덱스를 레이블로 사용하여 복제본을 훈련시켰습니다. 따라서 이러한 복제본을 평가하려면 클래스 인덱스도 제공해야 합니다. 클래스를 클래스 인덱스로 변환하기 위해 `LabelEncoder`를 사용할 수 있습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "l2cRUsm0Y91m"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "y_valid_encoded = encoder.fit_transform(y_valid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qw6J8XPSY91m"
      },
      "source": [
        "그러나 MNIST의 경우 숫자가 클래스 ID와 일치하므로 클래스 이름을 정수로 변환하는 것이 더 간단합니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "uqFxmRYnY91m"
      },
      "outputs": [],
      "source": [
        "y_valid_encoded = y_valid.astype(np.int64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWpeUFJCY91n"
      },
      "source": [
        "이제 분류기 복제본을 평가해 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXSQXcrCY91n",
        "outputId": "c95ca2e3-5420-450e-f110-610876554381"
      },
      "outputs": [],
      "source": [
        "[estimator.score(X_valid, y_valid_encoded)\n",
        " for estimator in voting_clf.estimators_]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sw68-OZ0Y91n"
      },
      "source": [
        "SVM을 제거하여 성능이 향상되는지 확인해 보겠습니다. 다음과 같이 `set_params()`를 사용하여 `\"drop\"`으로 설정하여 추정기를 제거할 수 있습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "-GQUp6ElY91n",
        "outputId": "a322bb72-e3ee-4fec-aeb3-182ebe0e797b"
      },
      "outputs": [],
      "source": [
        "voting_clf.set_params(svm_clf=\"drop\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unQWhYpcY91n"
      },
      "source": [
        "이렇게 하면 추정기 목록이 업데이트됩니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0oZmwX2Y91n",
        "outputId": "fecfef3f-4588-4a08-dbee-b269e3aff1db"
      },
      "outputs": [],
      "source": [
        "voting_clf.estimators"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNmhz-A9Y91n"
      },
      "source": [
        "그러나 _훈련된_ 추정기 목록은 업데이트하지 않습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLI5Mln9Y91n",
        "outputId": "dde5ffdf-6201-41cd-b7d0-1c9e2eb78d7f"
      },
      "outputs": [],
      "source": [
        "voting_clf.estimators_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4RedApsY91n",
        "outputId": "c5e71d39-65fe-4e21-ed50-2eade7859205"
      },
      "outputs": [],
      "source": [
        "voting_clf.named_estimators_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjfKS5-AY91n"
      },
      "source": [
        "따라서 `VotingClassifier`를 다시 훈련하거나 `estimators_`와 `named_estimators_`에 있는 훈련된 추정기 목록에서 SVM을 제거할 수 있습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "iSGRIlECY91o"
      },
      "outputs": [],
      "source": [
        "svm_clf_trained = voting_clf.named_estimators_.pop(\"svm_clf\")\n",
        "voting_clf.estimators_.remove(svm_clf_trained)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqtXrf6pY91o"
      },
      "source": [
        "이제 `VotingClassifier`를 다시 평가해 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KB2GCAflY91o",
        "outputId": "7cd4a9d1-223a-4f33-ec7f-d9f1c2fc1e25"
      },
      "outputs": [],
      "source": [
        "voting_clf.score(X_valid, y_valid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVWTT9E_Y91o"
      },
      "source": [
        "조금 나아졌습니다! SVM이 성능을 저해하고 있었습니다. 이제 간접 투표 분류기를 사용해 보겠습니다. 실제로 분류기를 재학습할 필요 없이 `voting`를 `soft`로 설정하면 됩니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "NcSuaRjzY91o"
      },
      "outputs": [],
      "source": [
        "voting_clf.voting = \"soft\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQAeEZiyY91o",
        "outputId": "d51410b8-6333-47f4-ceb0-0d9d03c6c743"
      },
      "outputs": [],
      "source": [
        "voting_clf.score(X_valid, y_valid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uoy-faPZY91o"
      },
      "source": [
        "이런, 이 경우에는 직접 투표 방식이 더 낫군요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUAwrhHNY91o"
      },
      "source": [
        "문제: _앙상블을 얻고 나면 테스트 세트로 확인해보세요. 개개의 분류기와 비교해서 성능이 얼마나 향상되나요?_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzznuxRiY91o",
        "outputId": "adee353a-3f24-4116-8387-ba6a686f0d8a"
      },
      "outputs": [],
      "source": [
        "voting_clf.voting = \"hard\"\n",
        "voting_clf.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_UyJ63RY91p",
        "outputId": "393f6cd9-64fd-47e3-c528-1346dfa56593"
      },
      "outputs": [],
      "source": [
        "[estimator.score(X_test, y_test.astype(np.int64))\n",
        " for estimator in voting_clf.estimators_]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwcOi-HGY91p"
      },
      "source": [
        "투표 분류기는 최고 모델의 오류율을 약 3%에서 2.7%로 낮췄으며, 이는 10%의 오류를 줄인 것입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnpWOw6AY91p"
      },
      "source": [
        "## 9. 스태킹 앙상블"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwNg5SZgY91p"
      },
      "source": [
        "문제: _이전 연습문제의 각 분류기를 실행해서 검증 세트에서 예측을 만들고 그 결과로 새로운 훈련 세트를 만들어보세요. 각 훈련 샘플은 하나의 이미지에 대한 전체 분류기의 예측을 담은 벡터이고 타깃은 이미지의 클래스입니다. 새로운 훈련 세트에 분류기 하나를 훈련시켜보세요._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "wxkw7FqcY91p"
      },
      "outputs": [],
      "source": [
        "X_valid_predictions = np.empty((len(X_valid), len(estimators)), dtype=object)\n",
        "\n",
        "for index, estimator in enumerate(estimators):\n",
        "    X_valid_predictions[:, index] = estimator.predict(X_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bl2o0gfUY91p",
        "outputId": "5e619435-2ccd-446b-abb7-2921fb348b00"
      },
      "outputs": [],
      "source": [
        "X_valid_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "CdMuDqGIY91p",
        "outputId": "3ee2db81-143e-4687-e4ac-98be6bc2980b"
      },
      "outputs": [],
      "source": [
        "rnd_forest_blender = RandomForestClassifier(n_estimators=200, oob_score=True,\n",
        "                                            random_state=42)\n",
        "rnd_forest_blender.fit(X_valid_predictions, y_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpweRZQtY91p",
        "outputId": "08dd533d-1913-4927-c853-0884e88cae33"
      },
      "outputs": [],
      "source": [
        "rnd_forest_blender.oob_score_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOW94ZPyY91p"
      },
      "source": [
        "이 블렌더를 미세 조정하거나 다른 유형의 블렌더(예: `MLPClassifier`)를 사용해 본 다음, 항상 그렇듯이 교차 검증을 통해 가장 적합한 블렌더를 선택할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9f_ROe_Y91q"
      },
      "source": [
        "문제: _축하합니다. 방금 블렌더를 훈련시켰습니다. 그리고 이 분류기를 모아서 스태킹 앙상블을 구성했습니다! 이제 테스트 세트에 앙상블을 평가해보세요. 테스트 세트의 각 이미지에 대해 모든 분류기로 예측을 만들고 앙상블의 예측 결과를 만들기 위해 블렌더에 그 예측을 주입합니다. 앞서 만든 투표 분류기와 비교하면 어떤가요?_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "2CjXP6ASY91q"
      },
      "outputs": [],
      "source": [
        "X_test_predictions = np.empty((len(X_test), len(estimators)), dtype=object)\n",
        "\n",
        "for index, estimator in enumerate(estimators):\n",
        "    X_test_predictions[:, index] = estimator.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "fpvIAEZdY91q"
      },
      "outputs": [],
      "source": [
        "y_pred = rnd_forest_blender.predict(X_test_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZUp4p9KY91q",
        "outputId": "54ff60cc-90fb-42e9-c2ac-a55ffca2891b"
      },
      "outputs": [],
      "source": [
        "accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hutlN63Y91q"
      },
      "source": [
        "이 스태킹 앙상블은 앞서 학습한 투표 기반 분류기보다 성능이 좋지 않습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTD-ADfSY91q"
      },
      "source": [
        "문제: _이제 `StackingClassifier`를 사용하여 다시 시도해 보세요. 성능이 더 좋아졌나요? 그렇다면 그 이유는 무엇인가요?_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kbeghjyY91q"
      },
      "source": [
        "`StackingClassifier`는 K-겹 교차 검증을 사용하기 때문에 별도의 검증 세트가 필요하지 않으므로 훈련 세트와 검증 세트를 더 큰 훈련 세트로 합쳐보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "yW8rJBM9Y91q"
      },
      "outputs": [],
      "source": [
        "X_train_full, y_train_full = X_mnist[:60_000], y_mnist[:60_000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YlvRoctY91q"
      },
      "source": [
        "이제 전체 훈련 세트에서 스태킹 분류기를 생성하고 훈련해 보겠습니다:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_kv_hALY91q"
      },
      "source": [
        "**경고**: 다음 셀은 기본적으로 5-겹 검증을 사용하기 때문에 실행하는 데 시간이 꽤 오래 걸립니다(하드웨어에 따라 15~30분 정도 소요). 이 셀은 4개의 분류기를 전체 훈련 세트의 80%에 대해 각각 5회씩 훈련하여 예측을 하고, 마지막으로 전체 훈련 세트에 대해 각각 한 번씩 훈련하여 예측에 대한 최종 모델을 훈련합니다. 총 25개의 모델을 훈련해야 합니다!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "bSxTUGg5Y91q",
        "outputId": "a37895f3-b56e-4274-b1de-513faddfcac1"
      },
      "outputs": [],
      "source": [
        "stack_clf = StackingClassifier(named_estimators,\n",
        "                               final_estimator=rnd_forest_blender)\n",
        "stack_clf.fit(X_train_full, y_train_full)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-dp87AYY91r",
        "outputId": "42c60b3e-dba0-4399-ce75-789f92d96a56"
      },
      "outputs": [],
      "source": [
        "stack_clf.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EutW6FsLY91r"
      },
      "source": [
        "`StackingClassifier`는 앞서 시도한 사용자 정의 스태킹 구현보다 훨씬 뛰어난 성능을 발휘합니다! 이는 크게 두 가지 이유 때문입니다:\n",
        "\n",
        "* 검증 세트를 별도로 사용하지 않았기 때문에 더 큰 데이터 집합에 대해 `StackingClassifier`를 학습시켰습니다.\n",
        "* 사용 가능한 경우 `predict_proba()`를, 그렇지 않으면 `decision_function()`을, 그렇지 않으면 `predict()`를 사용했습니다. 이렇게 하면 블렌더가 훨씬 더 미묘한 입력을 처리할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Re_RY1BgY91r"
      },
      "source": [
        "오늘은 여기까지입니다. 이 장의 코드와 연습 문제를 모두 완료하신 것을 축하드립니다!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "nav_menu": {
      "height": "252px",
      "width": "333px"
    },
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
